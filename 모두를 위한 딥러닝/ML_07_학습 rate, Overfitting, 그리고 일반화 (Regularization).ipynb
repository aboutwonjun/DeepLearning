{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d42ed73",
   "metadata": {},
   "source": [
    "https://m.blog.naver.com/ljh0326s/221231231739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56459be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:20:01.616299Z",
     "start_time": "2022-01-10T10:19:57.211157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2331d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:22:54.266846Z",
     "start_time": "2022-01-10T10:22:54.007641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.0573828 [[-1.1268083   1.021216    0.07323598]\n",
      " [-0.7791327   0.1695501  -0.7691781 ]\n",
      " [ 1.2845075   0.32257462  0.6730821 ]]\n",
      "1 1.4047546 [[-1.152967    1.0179513   0.10265939]\n",
      " [-0.83003616  0.14435232 -0.69307685]\n",
      " [ 1.2026721   0.33952066  0.7379714 ]]\n",
      "2 1.2415783 [[-1.1644204   1.0076879   0.12437617]\n",
      " [-0.80985564  0.07730163 -0.6462067 ]\n",
      " [ 1.1949928   0.3144123   0.77075917]]\n",
      "3 1.1831968 [[-1.1798362   1.0091002   0.13837963]\n",
      " [-0.8162237   0.07180721 -0.6343442 ]\n",
      " [ 1.164257    0.34674942  0.76915777]]\n",
      "4 1.1630486 [[-1.1891382   1.0064865   0.15029532]\n",
      " [-0.7920391   0.04379788 -0.63051945]\n",
      " [ 1.1652614   0.35690987  0.757993  ]]\n",
      "5 1.145642 [[-1.2014517   1.0068756   0.16221972]\n",
      " [-0.7842777   0.03225321 -0.6267362 ]\n",
      " [ 1.1502246   0.3821347   0.74780506]]\n",
      "6 1.1293168 [[-1.2118881   1.005512    0.17401978]\n",
      " [-0.767312    0.01108577 -0.62253445]\n",
      " [ 1.1449225   0.39758816  0.73765373]]\n",
      "7 1.1136439 [[-1.2233518   1.0053151   0.18568048]\n",
      " [-0.7564673  -0.00365444 -0.61863893]\n",
      " [ 1.1340013   0.41852278  0.72764033]]\n",
      "8 1.0985107 [[-1.2340353   1.0044571   0.19722185]\n",
      " [-0.7422162  -0.02196344 -0.614581  ]\n",
      " [ 1.1270118   0.43541023  0.7177423 ]]\n",
      "9 1.0838714 [[-1.2450832   1.0040975   0.20862938]\n",
      " [-0.7306173  -0.03745772 -0.61068565]\n",
      " [ 1.1178907   0.4543221   0.7079515 ]]\n",
      "10 1.0697078 [[-1.2557492   1.0034742   0.21991858]\n",
      " [-0.717732   -0.05428496 -0.6067437 ]\n",
      " [ 1.1105832   0.47129273  0.6982883 ]]\n",
      "11 1.05601 [[-1.2665261   1.0030876   0.23108198]\n",
      " [-0.70617694 -0.06967943 -0.6029043 ]\n",
      " [ 1.102473    0.4889534   0.6887378 ]]\n",
      "12 1.0427707 [[-1.2770783   1.0025918   0.24212992]\n",
      " [-0.6941815  -0.08550853 -0.59907067]\n",
      " [ 1.0953327   0.5055109   0.6793206 ]]\n",
      "13 1.0299834 [[-1.2876354   1.0022198   0.25305915]\n",
      " [-0.68296957 -0.10047451 -0.59531665]\n",
      " [ 1.0879393   0.52219945  0.6700255 ]]\n",
      "14 1.0176413 [[-1.2980347   1.0018014   0.2638768 ]\n",
      " [-0.67168146 -0.11548385 -0.5915954 ]\n",
      " [ 1.0811522   0.5381438   0.6608682 ]]\n",
      "15 1.0057373 [[-1.3083911   1.0014527   0.2745819 ]\n",
      " [-0.6609326  -0.12988141 -0.58794665]\n",
      " [ 1.0743558   0.5539667   0.65184176]]\n",
      "16 0.9942631 [[-1.3186197   1.0010835   0.2851797 ]\n",
      " [-0.65027505 -0.14413871 -0.58434695]\n",
      " [ 1.0679966   0.56921065  0.6429571 ]]\n",
      "17 0.9832107 [[-1.3287822   1.0007552   0.2956705 ]\n",
      " [-0.64003897 -0.15790258 -0.58081913]\n",
      " [ 1.0617424   0.58421177  0.6342101 ]]\n",
      "18 0.9725709 [[-1.3388315   1.0004166   0.30605838]\n",
      " [-0.6299749  -0.17143443 -0.57735133]\n",
      " [ 1.0558398   0.5987161   0.62560844]]\n",
      "19 0.96233416 [[-1.3488028   1.000102    0.31634426]\n",
      " [-0.6202704  -0.18453258 -0.5739577 ]\n",
      " [ 1.0500978   0.612917    0.61714953]]\n",
      "20 0.95249045 [[-1.3586687   0.99978065  0.3265315 ]\n",
      " [-0.6107776  -0.19735095 -0.57063204]\n",
      " [ 1.0446595   0.62666625  0.60883856]]\n",
      "21 0.9430287 [[-1.3684503   0.99947244  0.33662134]\n",
      " [-0.60160804 -0.20976879 -0.56738377]\n",
      " [ 1.0394084   0.6400821   0.60067374]]\n",
      "22 0.9339379 [[-1.3781309   0.99915785  0.34661663]\n",
      " [-0.5926689  -0.22188202 -0.5642097 ]\n",
      " [ 1.0344312   0.6530746   0.5926584 ]]\n",
      "23 0.92520666 [[-1.3877243   0.9988491   0.35651878]\n",
      " [-0.5840288  -0.23361568 -0.5611161 ]\n",
      " [ 1.0296526   0.6657207   0.58479095]]\n",
      "24 0.916823 [[-1.3972199   0.9985333   0.3663302 ]\n",
      " [-0.5756261  -0.24503313 -0.55810136]\n",
      " [ 1.0251266   0.67796427  0.5770734 ]]\n",
      "25 0.9087748 [[-1.406627    0.9982183   0.37605238]\n",
      " [-0.56750405 -0.25608665 -0.5551698 ]\n",
      " [ 1.0208018   0.68985844  0.569504  ]]\n",
      "26 0.90104973 [[-1.415939    0.9978952   0.3856874 ]\n",
      " [-0.55961937 -0.26682058 -0.55232054]\n",
      " [ 1.0167127   0.7013678   0.5620837 ]]\n",
      "27 0.8936354 [[-1.4251624   0.9975693   0.39523676]\n",
      " [-0.55199987 -0.27720416 -0.5495565 ]\n",
      " [ 1.0128222   0.7125314   0.55481064]]\n",
      "28 0.88651943 [[-1.4342932   0.9972345   0.4047023 ]\n",
      " [-0.54461324 -0.28727037 -0.5468769 ]\n",
      " [ 1.0091527   0.7233269   0.54768467]]\n",
      "29 0.8796891 [[-1.4433362   0.99689454  0.41408545]\n",
      " [-0.5374774  -0.2969994  -0.54428375]\n",
      " [ 1.0056759   0.7337846   0.5407037 ]]\n",
      "30 0.8731325 [[-1.4522891   0.9965449   0.4233879 ]\n",
      " [-0.53056717 -0.30641714 -0.5417762 ]\n",
      " [ 1.0024062   0.74389094  0.53386706]]\n",
      "31 0.86683726 [[-1.4611558   0.9961885   0.432611  ]\n",
      " [-0.5238938  -0.31551132 -0.5393554 ]\n",
      " [ 0.9993216   0.7536704   0.52717227]]\n",
      "32 0.8607912 [[-1.4699347   0.9958222   0.44175625]\n",
      " [-0.517437   -0.32430306 -0.53702044]\n",
      " [ 0.9964308   0.7631154   0.520618  ]]\n",
      "33 0.85498285 [[-1.4786294   0.9954482   0.45082492]\n",
      " [-0.51120335 -0.33278537 -0.53477174]\n",
      " [ 0.99371594  0.77224654  0.51420176]]\n",
      "34 0.84940064 [[-1.4872389   0.9950642   0.45981845]\n",
      " [-0.50517607 -0.34097612 -0.5326083 ]\n",
      " [ 0.99118215  0.78106046  0.50792164]]\n",
      "35 0.8440336 [[-1.4957664   0.9946721   0.46873802]\n",
      " [-0.49935848 -0.34887213 -0.53052986]\n",
      " [ 0.9888145   0.78957486  0.5017749 ]]\n",
      "36 0.83887076 [[-1.5042115   0.9942704   0.47758496]\n",
      " [-0.4937363  -0.35648888 -0.5285353 ]\n",
      " [ 0.98661536  0.7977894   0.49575946]]\n",
      "37 0.833902 [[-1.512577    0.9938605   0.48636037]\n",
      " [-0.48831058 -0.36382595 -0.52662396]\n",
      " [ 0.9845722   0.8057196   0.48987246]]\n",
      "38 0.8291172 [[-1.520863    0.9934414   0.49506548]\n",
      " [-0.483069   -0.37089705 -0.5247944 ]\n",
      " [ 0.98268557  0.8133672   0.4841115 ]]\n",
      "39 0.8245069 [[-1.529072    0.99301445  0.5037014 ]\n",
      " [-0.47801104 -0.37770364 -0.5230458 ]\n",
      " [ 0.9809446   0.82074606  0.47847363]]\n",
      "40 0.8200618 [[-1.5372044   0.992579    0.5122692 ]\n",
      " [-0.47312576 -0.38425824 -0.52137643]\n",
      " [ 0.9793488   0.82785916  0.47295636]]\n",
      "41 0.81577325 [[-1.5452623   0.9921362   0.52076995]\n",
      " [-0.46841183 -0.39056337 -0.5197852 ]\n",
      " [ 0.9778883   0.83471936  0.4675567 ]]\n",
      "42 0.81163293 [[-1.5532465   0.99168557  0.5292047 ]\n",
      " [-0.46385935 -0.39663067 -0.51827043]\n",
      " [ 0.976562    0.8413303   0.46227202]]\n",
      "43 0.80763286 [[-1.561159    0.9912283   0.53757447]\n",
      " [-0.45946634 -0.40246344 -0.5168307 ]\n",
      " [ 0.97536117  0.8477038   0.45709938]]\n",
      "44 0.80376565 [[-1.5690005   0.9907641   0.5458802 ]\n",
      " [-0.45522383 -0.4080725  -0.5154641 ]\n",
      " [ 0.9742841   0.85384405  0.45203617]]\n",
      "45 0.8000242 [[-1.576773    0.9902939   0.55412287]\n",
      " [-0.4511295  -0.41346171 -0.5141693 ]\n",
      " [ 0.973323    0.85976195  0.44707942]]\n",
      "46 0.7964016 [[-1.5844774   0.98981774  0.5623034 ]\n",
      " [-0.44717523 -0.418641   -0.5129442 ]\n",
      " [ 0.9724758   0.86546206  0.4422265 ]]\n",
      "47 0.7928916 [[-1.5921155   0.98933643  0.57042277]\n",
      " [-0.4433584  -0.42361468 -0.5117874 ]\n",
      " [ 0.9717356   0.8709542   0.43747458]]\n",
      "48 0.7894883 [[-1.5996882   0.98885006  0.57848185]\n",
      " [-0.4396717  -0.42839187 -0.51069695]\n",
      " [ 0.9711001   0.8762433   0.43282104]]\n",
      "49 0.78618586 [[-1.6071972   0.9883594   0.5864815 ]\n",
      " [-0.4361123  -0.43297708 -0.5096711 ]\n",
      " [ 0.97056293  0.88133836  0.4282631 ]]\n",
      "50 0.7829791 [[-1.6146433   0.9878645   0.5944226 ]\n",
      " [-0.43267366 -0.43737876 -0.50870806]\n",
      " [ 0.9701219   0.88624424  0.42379823]]\n",
      "51 0.77986276 [[-1.6220284   0.9873662   0.60230595]\n",
      " [-0.42935288 -0.44160149 -0.5078061 ]\n",
      " [ 0.96977127  0.89096934  0.4194238 ]]\n",
      "52 0.77683246 [[-1.6293532   0.9868646   0.6101324 ]\n",
      " [-0.42614394 -0.44565314 -0.5069634 ]\n",
      " [ 0.96950877  0.89551836  0.4151373 ]]\n",
      "53 0.7738836 [[-1.6366193   0.98636043  0.61790276]\n",
      " [-0.42304415 -0.44953817 -0.50617814]\n",
      " [ 0.9693291   0.8998991   0.41093618]]\n",
      "54 0.77101177 [[-1.6438278   0.9858538   0.6256178 ]\n",
      " [-0.4200479  -0.45326394 -0.50544864]\n",
      " [ 0.9692302   0.90411615  0.4068181 ]]\n",
      "55 0.7682134 [[-1.65098     0.9853454   0.63327837]\n",
      " [-0.41715252 -0.45683482 -0.50477314]\n",
      " [ 0.9692073   0.90817654  0.4027806 ]]\n",
      "56 0.7654847 [[-1.6580768   0.98483545  0.6408852 ]\n",
      " [-0.41435307 -0.46025744 -0.50415   ]\n",
      " [ 0.9692581   0.91208494  0.39882135]]\n",
      "57 0.76282203 [[-1.6651195   0.98432446  0.64843893]\n",
      " [-0.41164684 -0.46353626 -0.50357735]\n",
      " [ 0.9693786   0.91584766  0.39493817]]\n",
      "58 0.76022243 [[-1.6721092   0.98381263  0.6559404 ]\n",
      " [-0.40902936 -0.4666774  -0.50305367]\n",
      " [ 0.96956646  0.9194692   0.39112878]]\n",
      "59 0.7576827 [[-1.6790471   0.98330057  0.66339034]\n",
      " [-0.40649807 -0.469685   -0.50257736]\n",
      " [ 0.96981806  0.9229554   0.38739097]]\n",
      "60 0.75519997 [[-1.6859341   0.9827884   0.6707894 ]\n",
      " [-0.40404892 -0.4725648  -0.5021467 ]\n",
      " [ 0.9701312   0.9263105   0.38372272]]\n",
      "61 0.7527716 [[-1.6927712   0.9822766   0.6781383 ]\n",
      " [-0.4016794  -0.47532076 -0.50176024]\n",
      " [ 0.9705026   0.92953986  0.38012195]]\n",
      "62 0.75039506 [[-1.6995595   0.9817655   0.68543774]\n",
      " [-0.39938587 -0.4779581  -0.5014164 ]\n",
      " [ 0.9709302   0.9326475   0.37658668]]\n",
      "63 0.74806786 [[-1.7063      0.9812554   0.69268835]\n",
      " [-0.39716607 -0.4804806  -0.50111365]\n",
      " [ 0.971411    0.93563855  0.37311494]]\n",
      "64 0.745788 [[-1.7129936   0.98074657  0.6998908 ]\n",
      " [-0.3950165  -0.4828933  -0.50085056]\n",
      " [ 0.97194314  0.93851644  0.36970487]]\n",
      "65 0.74355316 [[-1.7196413   0.9802394   0.70704573]\n",
      " [-0.39293516 -0.48519942 -0.5006257 ]\n",
      " [ 0.97252375  0.9412861   0.3663546 ]]\n",
      "66 0.74136156 [[-1.726244    0.979734    0.7141538 ]\n",
      " [-0.3909188  -0.48740375 -0.50043774]\n",
      " [ 0.97315127  0.9439508   0.36306244]]\n",
      "67 0.7392112 [[-1.7328026   0.9792308   0.72121567]\n",
      " [-0.38896552 -0.4895095  -0.50028527]\n",
      " [ 0.973823    0.9465149   0.35982656]]\n",
      "68 0.7371004 [[-1.739318    0.97873     0.72823185]\n",
      " [-0.38707247 -0.49152085 -0.50016695]\n",
      " [ 0.9745375   0.94898164  0.35664535]]\n",
      "69 0.7350275 [[-1.7457911   0.9782319   0.73520297]\n",
      " [-0.38523778 -0.49344096 -0.50008154]\n",
      " [ 0.9752923   0.951355    0.35351714]]\n",
      "70 0.732991 [[-1.7522225   0.97773665  0.7421296 ]\n",
      " [-0.38345888 -0.49527362 -0.5000278 ]\n",
      " [ 0.9760861   0.95363796  0.35044038]]\n",
      "71 0.7309895 [[-1.7586132   0.97724456  0.7490124 ]\n",
      " [-0.381734   -0.49702182 -0.5000045 ]\n",
      " [ 0.9769167   0.95583427  0.34741354]]\n",
      "72 0.72902155 [[-1.7649639   0.97675574  0.75585186]\n",
      " [-0.38006082 -0.4986891  -0.5000104 ]\n",
      " [ 0.9777827   0.95794666  0.34443513]]\n",
      "73 0.7270858 [[-1.7712754   0.97627056  0.7626486 ]\n",
      " [-0.37843776 -0.5002781  -0.5000444 ]\n",
      " [ 0.9786822   0.9599786   0.34150368]]\n",
      "74 0.7251813 [[-1.7775484   0.97578907  0.7694031 ]\n",
      " [-0.3768625  -0.5017923  -0.5001055 ]\n",
      " [ 0.97961414  0.96193254  0.3386178 ]]\n",
      "75 0.7233066 [[-1.7837838   0.9753115   0.77611595]\n",
      " [-0.37533373 -0.503234   -0.5001925 ]\n",
      " [ 0.9805765   0.9638119   0.33577615]]\n",
      "76 0.7214607 [[-1.7899821   0.974838    0.7827877 ]\n",
      " [-0.3738493  -0.50460654 -0.50030446]\n",
      " [ 0.98156834  0.9656188   0.33297744]]\n",
      "77 0.7196426 [[-1.796144    0.9743688   0.7894188 ]\n",
      " [-0.37240803 -0.505912   -0.5004403 ]\n",
      " [ 0.9825879   0.9673563   0.33022034]]\n",
      "78 0.7178514 [[-1.8022702   0.973904    0.79600984]\n",
      " [-0.3710079  -0.5071534  -0.500599  ]\n",
      " [ 0.98363423  0.9690266   0.32750365]]\n",
      "79 0.716086 [[-1.8083614   0.9734438   0.8025613 ]\n",
      " [-0.36964783 -0.5083327  -0.50077975]\n",
      " [ 0.98470575  0.97063255  0.32482618]]\n",
      "80 0.71434575 [[-1.8144182   0.9729883   0.8090736 ]\n",
      " [-0.3683259  -0.5094529  -0.5009815 ]\n",
      " [ 0.98580176  0.97217596  0.32218677]]\n",
      "81 0.7126297 [[-1.8204412   0.9725377   0.81554735]\n",
      " [-0.36704123 -0.5105156  -0.5012035 ]\n",
      " [ 0.98692054  0.97365963  0.31958428]]\n",
      "82 0.71093726 [[-1.8264312   0.972092    0.8219829 ]\n",
      " [-0.36579192 -0.5115236  -0.50144476]\n",
      " [ 0.98806167  0.9750852   0.31701764]]\n",
      "83 0.7092674 [[-1.8323885   0.97165143  0.8283808 ]\n",
      " [-0.36457735 -0.5124784  -0.5017045 ]\n",
      " [ 0.9892234   0.97645533  0.3144858 ]]\n",
      "84 0.70761955 [[-1.8383138   0.971216    0.83474153]\n",
      " [-0.3633956  -0.51338273 -0.5019819 ]\n",
      " [ 0.9904055   0.97777134  0.31198773]]\n",
      "85 0.705993 [[-1.8442078   0.970786    0.84106547]\n",
      " [-0.3622462  -0.5142378  -0.50227624]\n",
      " [ 0.99160624  0.9790359   0.30952242]]\n",
      "86 0.70438725 [[-1.8500707   0.97036123  0.8473531 ]\n",
      " [-0.36112723 -0.5150463  -0.5025867 ]\n",
      " [ 0.9928255   0.9802501   0.30708894]]\n",
      "87 0.7028015 [[-1.8559034   0.9699421   0.85360485]\n",
      " [-0.36003846 -0.5158091  -0.5029127 ]\n",
      " [ 0.9940616   0.98141664  0.30468634]]\n",
      "88 0.7012353 [[-1.8617061   0.96952844  0.8598212 ]\n",
      " [-0.35897794 -0.51652896 -0.50325334]\n",
      " [ 0.99531454  0.98253626  0.30231377]]\n",
      "89 0.6996883 [[-1.8674796   0.9691205   0.8660025 ]\n",
      " [-0.35794553 -0.5172066  -0.5036081 ]\n",
      " [ 0.99658275  0.9836115   0.2999703 ]]\n",
      "90 0.69815964 [[-1.873224    0.96871823  0.8721492 ]\n",
      " [-0.35693955 -0.51784444 -0.5039762 ]\n",
      " [ 0.9978662   0.9846432   0.29765517]]\n",
      "91 0.69664884 [[-1.8789402   0.96832186  0.8782618 ]\n",
      " [-0.35595977 -0.51844335 -0.5043571 ]\n",
      " [ 0.99916345  0.9856337   0.29536745]]\n",
      "92 0.69515574 [[-1.8846284   0.9679313   0.8843406 ]\n",
      " [-0.35500458 -0.5190055  -0.50475013]\n",
      " [ 1.0004745   0.98658365  0.2931064 ]]\n",
      "93 0.69367945 [[-1.8902892   0.96754664  0.890386  ]\n",
      " [-0.35407373 -0.5195317  -0.5051547 ]\n",
      " [ 1.001798    0.9874952   0.2908713 ]]\n",
      "94 0.69222 [[-1.8959229   0.967168    0.8963984 ]\n",
      " [-0.35316595 -0.5200239  -0.50557035]\n",
      " [ 1.003134    0.98836917  0.28866133]]\n",
      "95 0.6907766 [[-1.9015301   0.9667954   0.90237826]\n",
      " [-0.35228088 -0.5204829  -0.5059964 ]\n",
      " [ 1.0044813   0.9892074   0.28647584]]\n",
      "96 0.68934906 [[-1.9071112   0.9664288   0.90832585]\n",
      " [-0.35141727 -0.5209105  -0.50643235]\n",
      " [ 1.0058398   0.99001056  0.2843141 ]]\n",
      "97 0.68793696 [[-1.9126664   0.9660684   0.91424155]\n",
      " [-0.35057497 -0.5213074  -0.5068777 ]\n",
      " [ 1.0072085   0.99078053  0.28217542]]\n",
      "98 0.6865399 [[-1.9181963   0.96571404  0.9201258 ]\n",
      " [-0.3497527  -0.5216754  -0.507332  ]\n",
      " [ 1.0085872   0.9915179   0.2800592 ]]\n",
      "99 0.6851574 [[-1.9237013   0.96536595  0.9259789 ]\n",
      " [-0.3489503  -0.52201504 -0.5077948 ]\n",
      " [ 1.0099752   0.9922244   0.27796474]]\n",
      "100 0.68378955 [[-1.9291817   0.965024    0.93180126]\n",
      " [-0.34816664 -0.522328   -0.5082655 ]\n",
      " [ 1.0113723   0.9929005   0.2758915 ]]\n",
      "101 0.6824355 [[-1.934638    0.96468836  0.93759316]\n",
      " [-0.34740165 -0.5226148  -0.5087437 ]\n",
      " [ 1.0127776   0.9935479   0.27383885]]\n",
      "102 0.68109524 [[-1.9400704   0.9643589   0.943355  ]\n",
      " [-0.34665415 -0.5228769  -0.509229  ]\n",
      " [ 1.014191    0.9941671   0.2718062 ]]\n",
      "103 0.67976844 [[-1.9454794   0.96403575  0.94908714]\n",
      " [-0.345924   -0.52311504 -0.50972104]\n",
      " [ 1.0156119   0.9947594   0.26979303]]\n",
      "104 0.6784548 [[-1.9508653   0.9637189   0.9547899 ]\n",
      " [-0.34521046 -0.5233302  -0.51021934]\n",
      " [ 1.0170399   0.99532557  0.26779878]]\n",
      "105 0.67715394 [[-1.9562283   0.9634083   0.9604635 ]\n",
      " [-0.34451303 -0.5235234  -0.5107236 ]\n",
      " [ 1.0184747   0.9958666   0.26582292]]\n",
      "106 0.67586577 [[-1.9615688   0.963104    0.9661084 ]\n",
      " [-0.3438312  -0.5236954  -0.5112334 ]\n",
      " [ 1.0199159   0.99638337  0.26386493]]\n",
      "107 0.67459 [[-1.9668874   0.96280605  0.9717248 ]\n",
      " [-0.34316453 -0.5238471  -0.5117484 ]\n",
      " [ 1.0213631   0.9968768   0.2619244 ]]\n",
      "108 0.6733262 [[-1.9721841   0.9625144   0.97731316]\n",
      " [-0.3425125  -0.52397937 -0.5122682 ]\n",
      " [ 1.022816    0.99734753  0.26000077]]\n",
      "109 0.67207426 [[-1.9774592   0.9622291   0.9828737 ]\n",
      " [-0.34187463 -0.5240929  -0.5127925 ]\n",
      " [ 1.0242741   0.9977965   0.2580936 ]]\n",
      "110 0.67083395 [[-1.9827132   0.96195006  0.98840666]\n",
      " [-0.34125054 -0.52418846 -0.51332104]\n",
      " [ 1.0257374   0.9982244   0.25620246]]\n",
      "111 0.66960514 [[-1.9879463   0.9616774   0.99391246]\n",
      " [-0.34063977 -0.52426684 -0.51385343]\n",
      " [ 1.0272053   0.99863195  0.25432694]]\n",
      "112 0.6683874 [[-1.9931588   0.961411    0.9993913 ]\n",
      " [-0.34004194 -0.52432865 -0.51438946]\n",
      " [ 1.0286777   0.9990199   0.25246656]]\n",
      "113 0.6671807 [[-1.998351    0.96115094  1.0048436 ]\n",
      " [-0.3394566  -0.52437466 -0.51492876]\n",
      " [ 1.0301543   0.99938893  0.25062096]]\n",
      "114 0.66598463 [[-2.003523    0.9608972   1.0102695 ]\n",
      " [-0.3388835  -0.5244054  -0.5154711 ]\n",
      " [ 1.0316348   0.9997397   0.24878974]]\n",
      "115 0.66479933 [[-2.0086756   0.9606497   1.0156693 ]\n",
      " [-0.3383221  -0.5244217  -0.51601624]\n",
      " [ 1.033119    1.0000727   0.24697252]]\n",
      "116 0.66362417 [[-2.0138085   0.9604085   1.0210434 ]\n",
      " [-0.33777228 -0.5244239  -0.5165639 ]\n",
      " [ 1.0346065   1.0003889   0.24516892]]\n",
      "117 0.66245925 [[-2.018922    0.96017355  1.026392  ]\n",
      " [-0.33723345 -0.5244128  -0.5171138 ]\n",
      " [ 1.0360972   1.0006884   0.24337861]]\n",
      "118 0.6613045 [[-2.0240166   0.95994484  1.0317153 ]\n",
      " [-0.33670548 -0.5243888  -0.51766574]\n",
      " [ 1.0375909   1.0009722   0.24160124]]\n",
      "119 0.66015947 [[-2.0290926   0.95972234  1.0370136 ]\n",
      " [-0.33618796 -0.5243525  -0.51821953]\n",
      " [ 1.0390873   1.0012405   0.23983647]]\n",
      "120 0.6590241 [[-2.03415     0.9595061   1.0422873 ]\n",
      " [-0.33568063 -0.5243044  -0.5187749 ]\n",
      " [ 1.0405862   1.0014942   0.23808396]]\n",
      "121 0.6578983 [[-2.0391889   0.959296    1.0475365 ]\n",
      " [-0.33518314 -0.5242451  -0.5193317 ]\n",
      " [ 1.0420876   1.0017334   0.23634343]]\n",
      "122 0.6567818 [[-2.04421     0.9590921   1.0527614 ]\n",
      " [-0.3346953  -0.5241749  -0.51988965]\n",
      " [ 1.043591    1.0019588   0.23461455]]\n",
      "123 0.65567446 [[-2.0492132   0.9588943   1.0579625 ]\n",
      " [-0.33421683 -0.52409446 -0.5204486 ]\n",
      " [ 1.0450964   1.0021709   0.23289703]]\n",
      "124 0.65457606 [[-2.0541987   0.9587026   1.0631399 ]\n",
      " [-0.3337474  -0.5240041  -0.52100843]\n",
      " [ 1.0466037   1.0023701   0.23119055]]\n",
      "125 0.6534867 [[-2.0591671   0.9585171   1.0682938 ]\n",
      " [-0.33328685 -0.5239042  -0.5215689 ]\n",
      " [ 1.0481125   1.0025569   0.22949487]]\n",
      "126 0.65240604 [[-2.0641184   0.95833755  1.0734245 ]\n",
      " [-0.33283478 -0.52379537 -0.52212983]\n",
      " [ 1.0496229   1.0027317   0.22780973]]\n",
      "127 0.6513339 [[-2.0690527   0.9581641   1.0785321 ]\n",
      " [-0.3323911  -0.5236778  -0.5226911 ]\n",
      " [ 1.0511346   1.0028949   0.22613485]]\n",
      "128 0.6502702 [[-2.07397     0.9579966   1.0836171 ]\n",
      " [-0.33195555 -0.523552   -0.5232524 ]\n",
      " [ 1.0526476   1.0030468   0.22447   ]]\n",
      "129 0.649215 [[-2.078871    0.95783514  1.0886796 ]\n",
      " [-0.33152798 -0.5234182  -0.52381384]\n",
      " [ 1.0541615   1.0031879   0.2228149 ]]\n",
      "130 0.64816785 [[-2.0837557   0.9576796   1.0937197 ]\n",
      " [-0.33110803 -0.5232769  -0.5243751 ]\n",
      " [ 1.0556765   1.0033184   0.22116938]]\n",
      "131 0.64712876 [[-2.0886242   0.95753     1.0987378 ]\n",
      " [-0.3306956  -0.52312833 -0.5249361 ]\n",
      " [ 1.0571922   1.003439    0.21953312]]\n",
      "132 0.64609766 [[-2.0934768   0.9573863   1.1037341 ]\n",
      " [-0.3302905  -0.52297294 -0.5254966 ]\n",
      " [ 1.0587087   1.0035496   0.21790597]]\n",
      "133 0.64507437 [[-2.0983136   0.9572485   1.1087087 ]\n",
      " [-0.32989258 -0.5228108  -0.52605665]\n",
      " [ 1.0602256   1.0036509   0.21628766]]\n",
      "134 0.64405876 [[-2.1031346   0.9571165   1.113662  ]\n",
      " [-0.32950142 -0.5226426  -0.526616  ]\n",
      " [ 1.0617433   1.0037429   0.21467802]]\n",
      "135 0.6430508 [[-2.1079404   0.9569903   1.118594  ]\n",
      " [-0.3291172  -0.5224682  -0.52717453]\n",
      " [ 1.063261    1.0038264   0.21307684]]\n",
      "136 0.64205027 [[-2.112731    0.95686984  1.1235051 ]\n",
      " [-0.3287394  -0.5222883  -0.5277322 ]\n",
      " [ 1.0647793   1.003901    0.21148396]]\n",
      "137 0.6410572 [[-2.1175065   0.95675516  1.1283953 ]\n",
      " [-0.32836822 -0.52210283 -0.5282889 ]\n",
      " [ 1.0662975   1.0039676   0.2098991 ]]\n",
      "138 0.6400713 [[-2.122267    0.95664614  1.133265  ]\n",
      " [-0.32800314 -0.52191234 -0.5288445 ]\n",
      " [ 1.067816    1.004026    0.20832215]]\n",
      "139 0.63909256 [[-2.127013    0.9565428   1.1381143 ]\n",
      " [-0.32764435 -0.5217167  -0.5293989 ]\n",
      " [ 1.0693344   1.004077    0.2067529 ]]\n",
      "140 0.6381209 [[-2.1317444   0.95644504  1.1429434 ]\n",
      " [-0.3272914  -0.52151656 -0.52995205]\n",
      " [ 1.0708528   1.0041203   0.20519118]]\n",
      "141 0.637156 [[-2.1364613   0.9563529   1.1477525 ]\n",
      " [-0.32694435 -0.5213118  -0.5305038 ]\n",
      " [ 1.0723709   1.0041566   0.20363683]]\n",
      "142 0.63619816 [[-2.141164    0.9562663   1.1525419 ]\n",
      " [-0.32660288 -0.521103   -0.5310541 ]\n",
      " [ 1.0738889   1.0041858   0.20208968]]\n",
      "143 0.635247 [[-2.1458528   0.9561852   1.1573116 ]\n",
      " [-0.3262671  -0.52089006 -0.53160286]\n",
      " [ 1.0754064   1.0042083   0.20054957]]\n",
      "144 0.6343025 [[-2.1505275   0.9561096   1.1620618 ]\n",
      " [-0.3259366  -0.5206734  -0.53215003]\n",
      " [ 1.0769237   1.0042243   0.19901635]]\n",
      "145 0.6333645 [[-2.1551883   0.9560394   1.1667929 ]\n",
      " [-0.3256115  -0.52045304 -0.5326955 ]\n",
      " [ 1.0784404   1.0042341   0.19748987]]\n",
      "146 0.63243306 [[-2.1598356   0.95597464  1.1715049 ]\n",
      " [-0.3252915  -0.52022934 -0.5332392 ]\n",
      " [ 1.0799568   1.0042377   0.19597   ]]\n",
      "147 0.631508 [[-2.1644692   0.9559153   1.176198  ]\n",
      " [-0.32497665 -0.5200023  -0.53378105]\n",
      " [ 1.0814724   1.0042354   0.19445658]]\n",
      "148 0.6305893 [[-2.1690896   0.9558612   1.1808724 ]\n",
      " [-0.32466665 -0.5197723  -0.53432107]\n",
      " [ 1.0829875   1.0042274   0.19294947]]\n",
      "149 0.6296767 [[-2.1736968   0.95581245  1.1855284 ]\n",
      " [-0.32436156 -0.51953936 -0.5348591 ]\n",
      " [ 1.0845019   1.0042139   0.19144858]]\n",
      "150 0.6287703 [[-2.1782908   0.95576894  1.190166  ]\n",
      " [-0.32406116 -0.51930374 -0.53539515]\n",
      " [ 1.0860156   1.0041951   0.18995376]]\n",
      "151 0.62786984 [[-2.182872    0.9557307   1.1947855 ]\n",
      " [-0.32376543 -0.5190655  -0.53592914]\n",
      " [ 1.0875285   1.0041711   0.18846485]]\n",
      "152 0.6269754 [[-2.1874404   0.95569754  1.199387  ]\n",
      " [-0.3234742  -0.5188248  -0.53646106]\n",
      " [ 1.0890405   1.0041422   0.18698177]]\n",
      "153 0.62608683 [[-2.191996    0.9556696   1.2039706 ]\n",
      " [-0.32318738 -0.51858187 -0.5369908 ]\n",
      " [ 1.0905517   1.0041083   0.18550438]]\n",
      "154 0.62520427 [[-2.1965392   0.9556467   1.2085365 ]\n",
      " [-0.32290494 -0.5183368  -0.5375183 ]\n",
      " [ 1.092062    1.0040698   0.18403259]]\n",
      "155 0.6243272 [[-2.2010698   0.9556289   1.2130849 ]\n",
      " [-0.32262674 -0.5180897  -0.5380436 ]\n",
      " [ 1.0935713   1.0040268   0.18256627]]\n",
      "156 0.62345576 [[-2.205588    0.9556161   1.217616  ]\n",
      " [-0.32235274 -0.51784074 -0.53856665]\n",
      " [ 1.0950795   1.0039794   0.18110533]]\n",
      "157 0.62259007 [[-2.2100942   0.9556083   1.2221298 ]\n",
      " [-0.3220827  -0.5175901  -0.53908736]\n",
      " [ 1.096587    1.0039278   0.17964967]]\n",
      "158 0.62172985 [[-2.2145882   0.95560545  1.2266266 ]\n",
      " [-0.32181674 -0.51733774 -0.5396057 ]\n",
      " [ 1.0980932   1.0038722   0.17819917]]\n",
      "159 0.620875 [[-2.2190702   0.95560753  1.2311066 ]\n",
      " [-0.3215547  -0.5170839  -0.5401216 ]\n",
      " [ 1.0995983   1.0038124   0.17675376]]\n",
      "160 0.62002563 [[-2.2235403   0.95561445  1.23557   ]\n",
      " [-0.32129645 -0.5168286  -0.5406351 ]\n",
      " [ 1.1011022   1.0037489   0.17531332]]\n",
      "161 0.6191815 [[-2.2279987   0.95562625  1.2400166 ]\n",
      " [-0.321042   -0.516572   -0.54114616]\n",
      " [ 1.102605    1.0036817   0.17387776]]\n",
      "162 0.61834264 [[-2.2324455   0.9556428   1.2444469 ]\n",
      " [-0.32079116 -0.51631427 -0.54165477]\n",
      " [ 1.1041067   1.0036107   0.172447  ]]\n",
      "163 0.617509 [[-2.2368808   0.95566416  1.2488608 ]\n",
      " [-0.320544   -0.51605535 -0.54216087]\n",
      " [ 1.105607    1.0035365   0.17102094]]\n",
      "164 0.6166804 [[-2.2413046   0.9556902   1.2532587 ]\n",
      " [-0.3203003  -0.5157955  -0.5426644 ]\n",
      " [ 1.1071062   1.0034586   0.16959952]]\n",
      "165 0.61585677 [[-2.2457173   0.95572096  1.2576406 ]\n",
      " [-0.32006022 -0.51553464 -0.54316545]\n",
      " [ 1.108604    1.0033777   0.16818263]]\n",
      "166 0.6150382 [[-2.2501187   0.9557563   1.2620066 ]\n",
      " [-0.3198234  -0.51527303 -0.54366386]\n",
      " [ 1.1101006   1.0032934   0.1667702 ]]\n",
      "167 0.6142247 [[-2.254509    0.9557963   1.266357  ]\n",
      " [-0.31959003 -0.51501054 -0.5441597 ]\n",
      " [ 1.1115959   1.0032063   0.16536216]]\n",
      "168 0.6134159 [[-2.2588882   0.9558408   1.2706916 ]\n",
      " [-0.31935984 -0.51474756 -0.5446529 ]\n",
      " [ 1.1130899   1.0031159   0.16395847]]\n",
      "169 0.61261195 [[-2.2632565   0.9558899   1.275011  ]\n",
      " [-0.31913304 -0.51448375 -0.5451435 ]\n",
      " [ 1.1145824   1.0030229   0.162559  ]]\n",
      "170 0.6118127 [[-2.2676141   0.9559434   1.279315  ]\n",
      " [-0.31890923 -0.5142196  -0.5456314 ]\n",
      " [ 1.1160737   1.002927    0.16116373]]\n",
      "171 0.6110182 [[-2.271961    0.9560014   1.2836038 ]\n",
      " [-0.3186887  -0.5139548  -0.5461167 ]\n",
      " [ 1.1175635   1.0028284   0.15977256]]\n",
      "172 0.61022824 [[-2.276297    0.9560638   1.2878776 ]\n",
      " [-0.31847107 -0.5136898  -0.5465993 ]\n",
      " [ 1.1190519   1.002727    0.15838543]]\n",
      "173 0.60944295 [[-2.2806227   0.9561306   1.2921364 ]\n",
      " [-0.31825662 -0.51342434 -0.5470793 ]\n",
      " [ 1.1205388   1.0026233   0.15700224]]\n",
      "174 0.6086622 [[-2.284938    0.95620173  1.2963805 ]\n",
      " [-0.31804493 -0.51315874 -0.5475566 ]\n",
      " [ 1.1220244   1.002517    0.15562299]]\n",
      "175 0.60788596 [[-2.289243    0.9562772   1.30061   ]\n",
      " [-0.31783625 -0.51289284 -0.54803115]\n",
      " [ 1.1235085   1.0024084   0.15424757]]\n",
      "176 0.60711396 [[-2.2935376   0.95635694  1.304825  ]\n",
      " [-0.3176304  -0.5126268  -0.54850304]\n",
      " [ 1.124991    1.0022974   0.15287593]]\n",
      "177 0.6063465 [[-2.2978222   0.9564409   1.3090255 ]\n",
      " [-0.31742734 -0.51236075 -0.5489722 ]\n",
      " [ 1.1264722   1.0021842   0.15150803]]\n",
      "178 0.6055833 [[-2.3020966   0.9565291   1.3132118 ]\n",
      " [-0.31722704 -0.51209456 -0.54943866]\n",
      " [ 1.1279519   1.0020688   0.1501438 ]]\n",
      "179 0.60482436 [[-2.306361    0.9566214   1.3173839 ]\n",
      " [-0.31702945 -0.51182836 -0.54990244]\n",
      " [ 1.1294299   1.0019512   0.14878319]]\n",
      "180 0.6040696 [[-2.3106155   0.95671785  1.321542  ]\n",
      " [-0.3168345  -0.5115623  -0.5503635 ]\n",
      " [ 1.1309066   1.0018317   0.14742617]]\n",
      "181 0.6033191 [[-2.3148603   0.9568184   1.3256862 ]\n",
      " [-0.3166422  -0.5112963  -0.5508218 ]\n",
      " [ 1.1323817   1.00171     0.14607266]]\n",
      "182 0.6025727 [[-2.3190954   0.956923    1.3298166 ]\n",
      " [-0.31645247 -0.5110304  -0.5512774 ]\n",
      " [ 1.1338552   1.0015866   0.14472261]]\n",
      "183 0.60183036 [[-2.3233206   0.9570316   1.3339332 ]\n",
      " [-0.31626526 -0.5107647  -0.5517303 ]\n",
      " [ 1.1353272   1.0014611   0.143376  ]]\n",
      "184 0.601092 [[-2.3275363   0.9571442   1.3380363 ]\n",
      " [-0.3160806  -0.51049924 -0.5521804 ]\n",
      " [ 1.1367977   1.001334    0.14203273]]\n",
      "185 0.6003577 [[-2.3317425   0.9572607   1.342126  ]\n",
      " [-0.31589833 -0.51023406 -0.55262786]\n",
      " [ 1.1382666   1.001205    0.14069279]]\n",
      "186 0.5996274 [[-2.3359392   0.9573812   1.3462024 ]\n",
      " [-0.3157185  -0.5099691  -0.5530726 ]\n",
      " [ 1.1397339   1.0010743   0.13935614]]\n",
      "187 0.5989009 [[-2.3401265   0.9575055   1.3502655 ]\n",
      " [-0.31554106 -0.5097046  -0.5535146 ]\n",
      " [ 1.1411997   1.000942    0.13802272]]\n",
      "188 0.59817815 [[-2.3443046   0.9576337   1.3543155 ]\n",
      " [-0.31536603 -0.5094403  -0.5539539 ]\n",
      " [ 1.1426638   1.0008081   0.1366925 ]]\n",
      "189 0.5974595 [[-2.3484735   0.95776564  1.3583524 ]\n",
      " [-0.31519318 -0.50917655 -0.5543905 ]\n",
      " [ 1.1441265   1.0006725   0.13536543]]\n",
      "190 0.5967444 [[-2.3526332   0.9579014   1.3623765 ]\n",
      " [-0.31502274 -0.5089131  -0.55482435]\n",
      " [ 1.1455874   1.0005355   0.13404147]]\n",
      "191 0.5960331 [[-2.3567839   0.9580409   1.3663877 ]\n",
      " [-0.31485438 -0.50865024 -0.55525553]\n",
      " [ 1.1470469   1.0003968   0.13272059]]\n",
      "192 0.5953256 [[-2.3609257   0.9581841   1.3703862 ]\n",
      " [-0.31468838 -0.50838774 -0.55568403]\n",
      " [ 1.1485047   1.0002569   0.13140273]]\n",
      "193 0.5946215 [[-2.3650584   0.958331    1.3743721 ]\n",
      " [-0.31452453 -0.5081258  -0.55610985]\n",
      " [ 1.149961    1.0001155   0.13008787]]\n",
      "194 0.5939213 [[-2.3691823   0.9584815   1.3783455 ]\n",
      " [-0.3143628  -0.50786436 -0.556533  ]\n",
      " [ 1.1514156   0.9999728   0.12877595]]\n",
      "195 0.5932244 [[-2.3732975   0.9586356   1.3823065 ]\n",
      " [-0.31420314 -0.5076035  -0.55695343]\n",
      " [ 1.1528686   0.99982876  0.12746699]]\n",
      "196 0.59253114 [[-2.377404    0.95879334  1.3862551 ]\n",
      " [-0.31404564 -0.5073432  -0.55737126]\n",
      " [ 1.15432     0.9996835   0.1261609 ]]\n",
      "197 0.59184146 [[-2.3815017   0.9589546   1.3901917 ]\n",
      " [-0.31389007 -0.5070836  -0.5577864 ]\n",
      " [ 1.15577     0.9995368   0.1248577 ]]\n",
      "198 0.5911552 [[-2.3855908   0.9591194   1.394116  ]\n",
      " [-0.31373674 -0.50682443 -0.5581989 ]\n",
      " [ 1.157218    0.9993892   0.1235573 ]]\n",
      "199 0.5904723 [[-2.3896713   0.9592876   1.3980285 ]\n",
      " [-0.3135852  -0.50656617 -0.5586088 ]\n",
      " [ 1.1586646   0.9992401   0.12225971]]\n",
      "200 0.58979285 [[-2.3937435   0.9594593   1.401929  ]\n",
      " [-0.31343576 -0.5063083  -0.55901605]\n",
      " [ 1.1601094   0.9990901   0.12096485]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], #one - hot으로 주어짐\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset / 학습시는 사용안함\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "#X,Y 값 선언\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "#Learning rate 주의! Overshooting, or Too small rate\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1)) #원핫인코딩\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1873ea64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T10:26:39.134538Z",
     "start_time": "2022-01-10T10:26:38.943565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  0.21421936 \n",
      "Prediction:\n",
      " [[1.2722099 ]\n",
      " [1.7623804 ]\n",
      " [1.2245902 ]\n",
      " [0.6203725 ]\n",
      " [0.93639994]\n",
      " [0.75640047]\n",
      " [0.3154993 ]\n",
      " [0.29413295]]\n",
      "1 Cost:  0.21420589 \n",
      "Prediction:\n",
      " [[1.2721891 ]\n",
      " [1.7623591 ]\n",
      " [1.2245729 ]\n",
      " [0.62035936]\n",
      " [0.9363843 ]\n",
      " [0.7563852 ]\n",
      " [0.3154891 ]\n",
      " [0.29412246]]\n",
      "2 Cost:  0.21419245 \n",
      "Prediction:\n",
      " [[1.2721685 ]\n",
      " [1.7623379 ]\n",
      " [1.2245555 ]\n",
      " [0.6203463 ]\n",
      " [0.9363686 ]\n",
      " [0.75637007]\n",
      " [0.31547895]\n",
      " [0.29411212]]\n",
      "3 Cost:  0.21417898 \n",
      "Prediction:\n",
      " [[1.2721478 ]\n",
      " [1.7623167 ]\n",
      " [1.2245381 ]\n",
      " [0.62033325]\n",
      " [0.9363529 ]\n",
      " [0.75635487]\n",
      " [0.31546873]\n",
      " [0.29410166]]\n",
      "4 Cost:  0.21416551 \n",
      "Prediction:\n",
      " [[1.2721272 ]\n",
      " [1.7622955 ]\n",
      " [1.2245207 ]\n",
      " [0.62032014]\n",
      " [0.9363372 ]\n",
      " [0.75633967]\n",
      " [0.31545854]\n",
      " [0.29409122]]\n",
      "5 Cost:  0.21415211 \n",
      "Prediction:\n",
      " [[1.2721065 ]\n",
      " [1.7622744 ]\n",
      " [1.2245034 ]\n",
      " [0.620307  ]\n",
      " [0.93632156]\n",
      " [0.75632447]\n",
      " [0.31544828]\n",
      " [0.2940808 ]]\n",
      "6 Cost:  0.2141387 \n",
      "Prediction:\n",
      " [[1.2720859 ]\n",
      " [1.7622533 ]\n",
      " [1.224486  ]\n",
      " [0.620294  ]\n",
      " [0.9363059 ]\n",
      " [0.7563094 ]\n",
      " [0.31543812]\n",
      " [0.2940704 ]]\n",
      "7 Cost:  0.21412522 \n",
      "Prediction:\n",
      " [[1.2720652 ]\n",
      " [1.7622321 ]\n",
      " [1.2244686 ]\n",
      " [0.6202808 ]\n",
      " [0.93629014]\n",
      " [0.75629413]\n",
      " [0.3154279 ]\n",
      " [0.29406   ]]\n",
      "8 Cost:  0.21411176 \n",
      "Prediction:\n",
      " [[1.2720445 ]\n",
      " [1.7622108 ]\n",
      " [1.2244512 ]\n",
      " [0.62026775]\n",
      " [0.9362744 ]\n",
      " [0.7562789 ]\n",
      " [0.3154177 ]\n",
      " [0.29404956]]\n",
      "9 Cost:  0.21409833 \n",
      "Prediction:\n",
      " [[1.2720238 ]\n",
      " [1.7621897 ]\n",
      " [1.2244338 ]\n",
      " [0.6202546 ]\n",
      " [0.9362588 ]\n",
      " [0.75626373]\n",
      " [0.31540745]\n",
      " [0.29403913]]\n",
      "10 Cost:  0.21408486 \n",
      "Prediction:\n",
      " [[1.2720032 ]\n",
      " [1.7621685 ]\n",
      " [1.2244164 ]\n",
      " [0.6202415 ]\n",
      " [0.93624306]\n",
      " [0.7562486 ]\n",
      " [0.3153973 ]\n",
      " [0.29402873]]\n",
      "11 Cost:  0.21407142 \n",
      "Prediction:\n",
      " [[1.2719824 ]\n",
      " [1.7621473 ]\n",
      " [1.2243991 ]\n",
      " [0.6202284 ]\n",
      " [0.9362274 ]\n",
      " [0.7562334 ]\n",
      " [0.31538707]\n",
      " [0.29401833]]\n",
      "12 Cost:  0.214058 \n",
      "Prediction:\n",
      " [[1.2719619 ]\n",
      " [1.7621262 ]\n",
      " [1.2243817 ]\n",
      " [0.6202153 ]\n",
      " [0.93621165]\n",
      " [0.75621814]\n",
      " [0.31537688]\n",
      " [0.2940079 ]]\n",
      "13 Cost:  0.21404454 \n",
      "Prediction:\n",
      " [[1.2719412 ]\n",
      " [1.762105  ]\n",
      " [1.2243644 ]\n",
      " [0.6202022 ]\n",
      " [0.9361959 ]\n",
      " [0.75620294]\n",
      " [0.31536663]\n",
      " [0.29399747]]\n",
      "14 Cost:  0.2140311 \n",
      "Prediction:\n",
      " [[1.2719206 ]\n",
      " [1.7620838 ]\n",
      " [1.224347  ]\n",
      " [0.6201891 ]\n",
      " [0.93618035]\n",
      " [0.7561878 ]\n",
      " [0.31535646]\n",
      " [0.293987  ]]\n",
      "15 Cost:  0.21401767 \n",
      "Prediction:\n",
      " [[1.2718998 ]\n",
      " [1.7620625 ]\n",
      " [1.2243297 ]\n",
      " [0.620176  ]\n",
      " [0.9361646 ]\n",
      " [0.7561726 ]\n",
      " [0.31534624]\n",
      " [0.29397666]]\n",
      "16 Cost:  0.21400423 \n",
      "Prediction:\n",
      " [[1.2718792 ]\n",
      " [1.7620414 ]\n",
      " [1.2243123 ]\n",
      " [0.6201629 ]\n",
      " [0.9361489 ]\n",
      " [0.7561574 ]\n",
      " [0.315336  ]\n",
      " [0.29396617]]\n",
      "17 Cost:  0.21399072 \n",
      "Prediction:\n",
      " [[1.2718585 ]\n",
      " [1.7620201 ]\n",
      " [1.2242949 ]\n",
      " [0.6201498 ]\n",
      " [0.93613315]\n",
      " [0.7561422 ]\n",
      " [0.3153258 ]\n",
      " [0.29395574]]\n",
      "18 Cost:  0.21397728 \n",
      "Prediction:\n",
      " [[1.2718378 ]\n",
      " [1.761999  ]\n",
      " [1.2242773 ]\n",
      " [0.6201366 ]\n",
      " [0.9361174 ]\n",
      " [0.756127  ]\n",
      " [0.31531563]\n",
      " [0.29394534]]\n",
      "19 Cost:  0.21396388 \n",
      "Prediction:\n",
      " [[1.2718171 ]\n",
      " [1.7619779 ]\n",
      " [1.22426   ]\n",
      " [0.62012357]\n",
      " [0.93610185]\n",
      " [0.7561119 ]\n",
      " [0.3153054 ]\n",
      " [0.29393494]]\n",
      "20 Cost:  0.21395041 \n",
      "Prediction:\n",
      " [[1.2717965 ]\n",
      " [1.7619567 ]\n",
      " [1.2242427 ]\n",
      " [0.62011045]\n",
      " [0.936086  ]\n",
      " [0.75609666]\n",
      " [0.31529516]\n",
      " [0.2939245 ]]\n",
      "21 Cost:  0.213937 \n",
      "Prediction:\n",
      " [[1.2717758 ]\n",
      " [1.7619356 ]\n",
      " [1.2242253 ]\n",
      " [0.62009734]\n",
      " [0.9360704 ]\n",
      " [0.75608146]\n",
      " [0.31528497]\n",
      " [0.29391408]]\n",
      "22 Cost:  0.2139236 \n",
      "Prediction:\n",
      " [[1.2717552 ]\n",
      " [1.7619144 ]\n",
      " [1.224208  ]\n",
      " [0.6200843 ]\n",
      " [0.9360548 ]\n",
      " [0.7560663 ]\n",
      " [0.31527475]\n",
      " [0.29390368]]\n",
      "23 Cost:  0.21391015 \n",
      "Prediction:\n",
      " [[1.2717345 ]\n",
      " [1.7618932 ]\n",
      " [1.2241906 ]\n",
      " [0.6200712 ]\n",
      " [0.9360391 ]\n",
      " [0.75605106]\n",
      " [0.31526458]\n",
      " [0.29389328]]\n",
      "24 Cost:  0.21389669 \n",
      "Prediction:\n",
      " [[1.2717139 ]\n",
      " [1.7618719 ]\n",
      " [1.2241732 ]\n",
      " [0.6200582 ]\n",
      " [0.93602335]\n",
      " [0.7560359 ]\n",
      " [0.31525442]\n",
      " [0.29388288]]\n",
      "25 Cost:  0.2138833 \n",
      "Prediction:\n",
      " [[1.2716932 ]\n",
      " [1.7618508 ]\n",
      " [1.2241559 ]\n",
      " [0.62004507]\n",
      " [0.9360077 ]\n",
      " [0.7560207 ]\n",
      " [0.3152442 ]\n",
      " [0.29387242]]\n",
      "26 Cost:  0.2138699 \n",
      "Prediction:\n",
      " [[1.2716727 ]\n",
      " [1.7618297 ]\n",
      " [1.2241385 ]\n",
      " [0.62003195]\n",
      " [0.935992  ]\n",
      " [0.75600564]\n",
      " [0.31523404]\n",
      " [0.29386207]]\n",
      "27 Cost:  0.21385644 \n",
      "Prediction:\n",
      " [[1.271652  ]\n",
      " [1.7618085 ]\n",
      " [1.2241211 ]\n",
      " [0.6200189 ]\n",
      " [0.9359764 ]\n",
      " [0.75599045]\n",
      " [0.3152238 ]\n",
      " [0.2938516 ]]\n",
      "28 Cost:  0.21384306 \n",
      "Prediction:\n",
      " [[1.2716314 ]\n",
      " [1.7617874 ]\n",
      " [1.2241037 ]\n",
      " [0.62000585]\n",
      " [0.93596077]\n",
      " [0.75597537]\n",
      " [0.3152136 ]\n",
      " [0.2938412 ]]\n",
      "29 Cost:  0.21382964 \n",
      "Prediction:\n",
      " [[1.2716107 ]\n",
      " [1.7617662 ]\n",
      " [1.2240865 ]\n",
      " [0.61999273]\n",
      " [0.935945  ]\n",
      " [0.7559601 ]\n",
      " [0.31520343]\n",
      " [0.2938308 ]]\n",
      "30 Cost:  0.21381623 \n",
      "Prediction:\n",
      " [[1.2715901 ]\n",
      " [1.7617451 ]\n",
      " [1.2240691 ]\n",
      " [0.6199796 ]\n",
      " [0.9359294 ]\n",
      " [0.75594497]\n",
      " [0.31519327]\n",
      " [0.2938204 ]]\n",
      "31 Cost:  0.21380283 \n",
      "Prediction:\n",
      " [[1.2715695 ]\n",
      " [1.761724  ]\n",
      " [1.2240518 ]\n",
      " [0.61996657]\n",
      " [0.9359137 ]\n",
      " [0.7559298 ]\n",
      " [0.31518304]\n",
      " [0.29381007]]\n",
      "32 Cost:  0.21378943 \n",
      "Prediction:\n",
      " [[1.2715489 ]\n",
      " [1.7617029 ]\n",
      " [1.2240344 ]\n",
      " [0.6199535 ]\n",
      " [0.93589807]\n",
      " [0.75591457]\n",
      " [0.31517282]\n",
      " [0.2937996 ]]\n",
      "33 Cost:  0.21377602 \n",
      "Prediction:\n",
      " [[1.2715282 ]\n",
      " [1.7616818 ]\n",
      " [1.2240171 ]\n",
      " [0.6199404 ]\n",
      " [0.9358823 ]\n",
      " [0.7558995 ]\n",
      " [0.31516266]\n",
      " [0.2937892 ]]\n",
      "34 Cost:  0.21376261 \n",
      "Prediction:\n",
      " [[1.2715077 ]\n",
      " [1.7616606 ]\n",
      " [1.2239997 ]\n",
      " [0.6199274 ]\n",
      " [0.9358667 ]\n",
      " [0.7558843 ]\n",
      " [0.31515244]\n",
      " [0.2937788 ]]\n",
      "35 Cost:  0.21374922 \n",
      "Prediction:\n",
      " [[1.271487  ]\n",
      " [1.7616395 ]\n",
      " [1.2239825 ]\n",
      " [0.61991423]\n",
      " [0.9358511 ]\n",
      " [0.7558691 ]\n",
      " [0.31514227]\n",
      " [0.2937684 ]]\n",
      "36 Cost:  0.21373576 \n",
      "Prediction:\n",
      " [[1.2714664 ]\n",
      " [1.7616181 ]\n",
      " [1.223965  ]\n",
      " [0.6199012 ]\n",
      " [0.93583536]\n",
      " [0.755854  ]\n",
      " [0.31513205]\n",
      " [0.293758  ]]\n",
      "37 Cost:  0.21372238 \n",
      "Prediction:\n",
      " [[1.2714458 ]\n",
      " [1.7615972 ]\n",
      " [1.2239478 ]\n",
      " [0.61988807]\n",
      " [0.9358197 ]\n",
      " [0.7558388 ]\n",
      " [0.3151219 ]\n",
      " [0.2937476 ]]\n",
      "38 Cost:  0.213709 \n",
      "Prediction:\n",
      " [[1.2714251 ]\n",
      " [1.761576  ]\n",
      " [1.2239305 ]\n",
      " [0.61987495]\n",
      " [0.935804  ]\n",
      " [0.7558236 ]\n",
      " [0.31511167]\n",
      " [0.2937372 ]]\n",
      "39 Cost:  0.21369554 \n",
      "Prediction:\n",
      " [[1.2714045]\n",
      " [1.7615547]\n",
      " [1.2239131]\n",
      " [0.6198619]\n",
      " [0.9357884]\n",
      " [0.7558085]\n",
      " [0.3151015]\n",
      " [0.2937268]]\n",
      "40 Cost:  0.21368209 \n",
      "Prediction:\n",
      " [[1.2713839 ]\n",
      " [1.7615336 ]\n",
      " [1.2238954 ]\n",
      " [0.61984885]\n",
      " [0.9357728 ]\n",
      " [0.75579333]\n",
      " [0.31509128]\n",
      " [0.2937164 ]]\n",
      "41 Cost:  0.21366873 \n",
      "Prediction:\n",
      " [[1.2713633 ]\n",
      " [1.7615125 ]\n",
      " [1.2238781 ]\n",
      " [0.6198358 ]\n",
      " [0.9357571 ]\n",
      " [0.7557782 ]\n",
      " [0.31508112]\n",
      " [0.293706  ]]\n",
      "42 Cost:  0.21365538 \n",
      "Prediction:\n",
      " [[1.2713428 ]\n",
      " [1.7614915 ]\n",
      " [1.223861  ]\n",
      " [0.61982274]\n",
      " [0.9357414 ]\n",
      " [0.75576293]\n",
      " [0.3150709 ]\n",
      " [0.2936956 ]]\n",
      "43 Cost:  0.21364191 \n",
      "Prediction:\n",
      " [[1.271322  ]\n",
      " [1.7614702 ]\n",
      " [1.2238436 ]\n",
      " [0.6198096 ]\n",
      " [0.9357257 ]\n",
      " [0.75574785]\n",
      " [0.31506073]\n",
      " [0.2936852 ]]\n",
      "44 Cost:  0.2136285 \n",
      "Prediction:\n",
      " [[1.2713014 ]\n",
      " [1.7614491 ]\n",
      " [1.2238262 ]\n",
      " [0.6197965 ]\n",
      " [0.9357101 ]\n",
      " [0.75573266]\n",
      " [0.31505057]\n",
      " [0.2936748 ]]\n",
      "45 Cost:  0.21361509 \n",
      "Prediction:\n",
      " [[1.2712808 ]\n",
      " [1.7614279 ]\n",
      " [1.2238088 ]\n",
      " [0.6197835 ]\n",
      " [0.9356944 ]\n",
      " [0.7557176 ]\n",
      " [0.31504035]\n",
      " [0.2936644 ]]\n",
      "46 Cost:  0.21360171 \n",
      "Prediction:\n",
      " [[1.2712601 ]\n",
      " [1.7614068 ]\n",
      " [1.2237915 ]\n",
      " [0.6197704 ]\n",
      " [0.9356787 ]\n",
      " [0.7557024 ]\n",
      " [0.31503013]\n",
      " [0.293654  ]]\n",
      "47 Cost:  0.2135883 \n",
      "Prediction:\n",
      " [[1.2712395 ]\n",
      " [1.7613857 ]\n",
      " [1.2237741 ]\n",
      " [0.61975735]\n",
      " [0.9356631 ]\n",
      " [0.75568724]\n",
      " [0.31501997]\n",
      " [0.29364353]]\n",
      "48 Cost:  0.21357489 \n",
      "Prediction:\n",
      " [[1.2712189 ]\n",
      " [1.7613645 ]\n",
      " [1.2237568 ]\n",
      " [0.6197443 ]\n",
      " [0.93564737]\n",
      " [0.755672  ]\n",
      " [0.31500974]\n",
      " [0.2936332 ]]\n",
      "49 Cost:  0.21356145 \n",
      "Prediction:\n",
      " [[1.2711983 ]\n",
      " [1.7613432 ]\n",
      " [1.2237394 ]\n",
      " [0.6197312 ]\n",
      " [0.9356317 ]\n",
      " [0.75565684]\n",
      " [0.31499958]\n",
      " [0.29362273]]\n",
      "50 Cost:  0.21354811 \n",
      "Prediction:\n",
      " [[1.2711778 ]\n",
      " [1.7613223 ]\n",
      " [1.2237222 ]\n",
      " [0.6197181 ]\n",
      " [0.935616  ]\n",
      " [0.7556417 ]\n",
      " [0.31498936]\n",
      " [0.2936124 ]]\n",
      "51 Cost:  0.21353468 \n",
      "Prediction:\n",
      " [[1.271157  ]\n",
      " [1.761301  ]\n",
      " [1.2237048 ]\n",
      " [0.619705  ]\n",
      " [0.9356004 ]\n",
      " [0.7556265 ]\n",
      " [0.3149792 ]\n",
      " [0.29360193]]\n",
      "52 Cost:  0.21352126 \n",
      "Prediction:\n",
      " [[1.2711364 ]\n",
      " [1.7612798 ]\n",
      " [1.2236874 ]\n",
      " [0.61969197]\n",
      " [0.93558466]\n",
      " [0.7556114 ]\n",
      " [0.31496897]\n",
      " [0.29359153]]\n",
      "53 Cost:  0.21350789 \n",
      "Prediction:\n",
      " [[1.2711158 ]\n",
      " [1.7612588 ]\n",
      " [1.22367   ]\n",
      " [0.61967885]\n",
      " [0.9355691 ]\n",
      " [0.7555962 ]\n",
      " [0.31495875]\n",
      " [0.2935812 ]]\n",
      "54 Cost:  0.21349452 \n",
      "Prediction:\n",
      " [[1.2710952 ]\n",
      " [1.7612377 ]\n",
      " [1.2236528 ]\n",
      " [0.61966574]\n",
      " [0.93555343]\n",
      " [0.755581  ]\n",
      " [0.3149486 ]\n",
      " [0.29357073]]\n",
      "55 Cost:  0.2134811 \n",
      "Prediction:\n",
      " [[1.2710745 ]\n",
      " [1.7612165 ]\n",
      " [1.2236354 ]\n",
      " [0.6196527 ]\n",
      " [0.9355377 ]\n",
      " [0.7555659 ]\n",
      " [0.31493843]\n",
      " [0.29356033]]\n",
      "56 Cost:  0.21346767 \n",
      "Prediction:\n",
      " [[1.2710539 ]\n",
      " [1.7611953 ]\n",
      " [1.223618  ]\n",
      " [0.61963964]\n",
      " [0.93552196]\n",
      " [0.75555074]\n",
      " [0.3149282 ]\n",
      " [0.29354993]]\n",
      "57 Cost:  0.21345432 \n",
      "Prediction:\n",
      " [[1.2710333 ]\n",
      " [1.7611742 ]\n",
      " [1.2236009 ]\n",
      " [0.6196266 ]\n",
      " [0.9355064 ]\n",
      " [0.7555356 ]\n",
      " [0.31491804]\n",
      " [0.29353952]]\n",
      "58 Cost:  0.21344092 \n",
      "Prediction:\n",
      " [[1.2710128 ]\n",
      " [1.761153  ]\n",
      " [1.2235835 ]\n",
      " [0.6196135 ]\n",
      " [0.93549085]\n",
      " [0.75552034]\n",
      " [0.31490782]\n",
      " [0.29352912]]\n",
      "59 Cost:  0.21342751 \n",
      "Prediction:\n",
      " [[1.270992  ]\n",
      " [1.7611319 ]\n",
      " [1.223566  ]\n",
      " [0.61960036]\n",
      " [0.9354751 ]\n",
      " [0.75550526]\n",
      " [0.31489766]\n",
      " [0.29351872]]\n",
      "60 Cost:  0.2134141 \n",
      "Prediction:\n",
      " [[1.2709714 ]\n",
      " [1.7611108 ]\n",
      " [1.2235487 ]\n",
      " [0.6195873 ]\n",
      " [0.9354594 ]\n",
      " [0.75549006]\n",
      " [0.31488743]\n",
      " [0.29350832]]\n",
      "61 Cost:  0.21340066 \n",
      "Prediction:\n",
      " [[1.2709508 ]\n",
      " [1.7610896 ]\n",
      " [1.2235312 ]\n",
      " [0.6195742 ]\n",
      " [0.9354437 ]\n",
      " [0.75547487]\n",
      " [0.31487727]\n",
      " [0.29349792]]\n",
      "62 Cost:  0.21338731 \n",
      "Prediction:\n",
      " [[1.2709302 ]\n",
      " [1.7610685 ]\n",
      " [1.223514  ]\n",
      " [0.6195611 ]\n",
      " [0.93542814]\n",
      " [0.7554598 ]\n",
      " [0.31486705]\n",
      " [0.29348752]]\n",
      "63 Cost:  0.21337388 \n",
      "Prediction:\n",
      " [[1.2709095 ]\n",
      " [1.7610472 ]\n",
      " [1.2234966 ]\n",
      " [0.6195481 ]\n",
      " [0.9354123 ]\n",
      " [0.7554445 ]\n",
      " [0.3148569 ]\n",
      " [0.29347712]]\n",
      "64 Cost:  0.21336052 \n",
      "Prediction:\n",
      " [[1.2708889 ]\n",
      " [1.7610263 ]\n",
      " [1.2234792 ]\n",
      " [0.61953497]\n",
      " [0.9353967 ]\n",
      " [0.7554294 ]\n",
      " [0.31484666]\n",
      " [0.29346672]]\n",
      "65 Cost:  0.21334712 \n",
      "Prediction:\n",
      " [[1.2708683 ]\n",
      " [1.7610049 ]\n",
      " [1.2234619 ]\n",
      " [0.619522  ]\n",
      " [0.9353811 ]\n",
      " [0.75541425]\n",
      " [0.3148365 ]\n",
      " [0.29345632]]\n",
      "66 Cost:  0.21333376 \n",
      "Prediction:\n",
      " [[1.2708478 ]\n",
      " [1.760984  ]\n",
      " [1.2234446 ]\n",
      " [0.61950886]\n",
      " [0.93536544]\n",
      " [0.7553991 ]\n",
      " [0.31482628]\n",
      " [0.29344591]]\n",
      "67 Cost:  0.21332033 \n",
      "Prediction:\n",
      " [[1.270827  ]\n",
      " [1.7609627 ]\n",
      " [1.2234272 ]\n",
      " [0.61949575]\n",
      " [0.9353497 ]\n",
      " [0.7553839 ]\n",
      " [0.31481612]\n",
      " [0.2934355 ]]\n",
      "68 Cost:  0.2133069 \n",
      "Prediction:\n",
      " [[1.2708064 ]\n",
      " [1.7609415 ]\n",
      " [1.2234098 ]\n",
      " [0.61948276]\n",
      " [0.93533397]\n",
      " [0.7553687 ]\n",
      " [0.3148059 ]\n",
      " [0.2934251 ]]\n",
      "69 Cost:  0.21329357 \n",
      "Prediction:\n",
      " [[1.2707858 ]\n",
      " [1.7609205 ]\n",
      " [1.2233925 ]\n",
      " [0.61946964]\n",
      " [0.9353184 ]\n",
      " [0.7553536 ]\n",
      " [0.31479567]\n",
      " [0.2934147 ]]\n",
      "70 Cost:  0.21328017 \n",
      "Prediction:\n",
      " [[1.2707652 ]\n",
      " [1.7608993 ]\n",
      " [1.2233752 ]\n",
      " [0.6194565 ]\n",
      " [0.93530273]\n",
      " [0.75533843]\n",
      " [0.3147855 ]\n",
      " [0.2934043 ]]\n",
      "71 Cost:  0.21326676 \n",
      "Prediction:\n",
      " [[1.2707446 ]\n",
      " [1.7608781 ]\n",
      " [1.2233578 ]\n",
      " [0.6194435 ]\n",
      " [0.9352871 ]\n",
      " [0.7553233 ]\n",
      " [0.3147753 ]\n",
      " [0.29339385]]\n",
      "72 Cost:  0.21325342 \n",
      "Prediction:\n",
      " [[1.270724  ]\n",
      " [1.7608571 ]\n",
      " [1.2233405 ]\n",
      " [0.6194304 ]\n",
      " [0.93527144]\n",
      " [0.7553081 ]\n",
      " [0.31476516]\n",
      " [0.29338354]]\n",
      "73 Cost:  0.21324004 \n",
      "Prediction:\n",
      " [[1.2707034 ]\n",
      " [1.7608359 ]\n",
      " [1.2233232 ]\n",
      " [0.61941737]\n",
      " [0.93525577]\n",
      " [0.755293  ]\n",
      " [0.31475496]\n",
      " [0.2933731 ]]\n",
      "74 Cost:  0.21322662 \n",
      "Prediction:\n",
      " [[1.2706828 ]\n",
      " [1.7608147 ]\n",
      " [1.2233058 ]\n",
      " [0.6194043 ]\n",
      " [0.93524003]\n",
      " [0.7552779 ]\n",
      " [0.3147448 ]\n",
      " [0.2933627 ]]\n",
      "75 Cost:  0.21321328 \n",
      "Prediction:\n",
      " [[1.2706622 ]\n",
      " [1.7607937 ]\n",
      " [1.2232885 ]\n",
      " [0.6193912 ]\n",
      " [0.9352245 ]\n",
      " [0.7552627 ]\n",
      " [0.31473464]\n",
      " [0.2933523 ]]\n",
      "76 Cost:  0.21319991 \n",
      "Prediction:\n",
      " [[1.2706416 ]\n",
      " [1.7607726 ]\n",
      " [1.2232713 ]\n",
      " [0.61937815]\n",
      " [0.9352088 ]\n",
      " [0.7552476 ]\n",
      " [0.31472445]\n",
      " [0.29334193]]\n",
      "77 Cost:  0.21318652 \n",
      "Prediction:\n",
      " [[1.270621  ]\n",
      " [1.7607514 ]\n",
      " [1.2232538 ]\n",
      " [0.6193651 ]\n",
      " [0.93519324]\n",
      " [0.7552324 ]\n",
      " [0.3147143 ]\n",
      " [0.29333156]]\n",
      "78 Cost:  0.21317315 \n",
      "Prediction:\n",
      " [[1.2706003 ]\n",
      " [1.7607303 ]\n",
      " [1.2232366 ]\n",
      " [0.619352  ]\n",
      " [0.93517756]\n",
      " [0.7552173 ]\n",
      " [0.3147041 ]\n",
      " [0.29332116]]\n",
      "79 Cost:  0.21315975 \n",
      "Prediction:\n",
      " [[1.2705797 ]\n",
      " [1.7607092 ]\n",
      " [1.2232192 ]\n",
      " [0.6193389 ]\n",
      " [0.9351618 ]\n",
      " [0.7552021 ]\n",
      " [0.31469393]\n",
      " [0.29331076]]\n",
      "80 Cost:  0.21314639 \n",
      "Prediction:\n",
      " [[1.2705591 ]\n",
      " [1.7606881 ]\n",
      " [1.2232018 ]\n",
      " [0.61932594]\n",
      " [0.9351463 ]\n",
      " [0.7551869 ]\n",
      " [0.31468374]\n",
      " [0.2933004 ]]\n",
      "81 Cost:  0.21313302 \n",
      "Prediction:\n",
      " [[1.2705386 ]\n",
      " [1.7606668 ]\n",
      " [1.2231845 ]\n",
      " [0.6193129 ]\n",
      " [0.9351306 ]\n",
      " [0.75517184]\n",
      " [0.3146736 ]\n",
      " [0.29329002]]\n",
      "82 Cost:  0.21311966 \n",
      "Prediction:\n",
      " [[1.270518  ]\n",
      " [1.7606457 ]\n",
      " [1.2231672 ]\n",
      " [0.61929977]\n",
      " [0.935115  ]\n",
      " [0.75515664]\n",
      " [0.31466338]\n",
      " [0.29327962]]\n",
      "83 Cost:  0.21310627 \n",
      "Prediction:\n",
      " [[1.2704973 ]\n",
      " [1.7606246 ]\n",
      " [1.2231498 ]\n",
      " [0.61928666]\n",
      " [0.9350993 ]\n",
      " [0.75514156]\n",
      " [0.31465322]\n",
      " [0.29326922]]\n",
      "84 Cost:  0.2130929 \n",
      "Prediction:\n",
      " [[1.2704767 ]\n",
      " [1.7606034 ]\n",
      " [1.2231325 ]\n",
      " [0.61927366]\n",
      " [0.9350836 ]\n",
      " [0.75512636]\n",
      " [0.31464303]\n",
      " [0.29325885]]\n",
      "85 Cost:  0.21307948 \n",
      "Prediction:\n",
      " [[1.2704561 ]\n",
      " [1.7605822 ]\n",
      " [1.2231151 ]\n",
      " [0.61926055]\n",
      " [0.93506795]\n",
      " [0.7551113 ]\n",
      " [0.31463283]\n",
      " [0.29324847]]\n",
      "86 Cost:  0.21306619 \n",
      "Prediction:\n",
      " [[1.2704355 ]\n",
      " [1.7605613 ]\n",
      " [1.2230978 ]\n",
      " [0.61924756]\n",
      " [0.9350524 ]\n",
      " [0.7550961 ]\n",
      " [0.31462267]\n",
      " [0.29323807]]\n",
      "87 Cost:  0.21305275 \n",
      "Prediction:\n",
      " [[1.2704148 ]\n",
      " [1.76054   ]\n",
      " [1.2230805 ]\n",
      " [0.6192345 ]\n",
      " [0.93503666]\n",
      " [0.75508094]\n",
      " [0.3146125 ]\n",
      " [0.29322767]]\n",
      "88 Cost:  0.21303946 \n",
      "Prediction:\n",
      " [[1.2703943 ]\n",
      " [1.760519  ]\n",
      " [1.2230632 ]\n",
      " [0.61922145]\n",
      " [0.9350211 ]\n",
      " [0.7550658 ]\n",
      " [0.31460232]\n",
      " [0.2932173 ]]\n",
      "89 Cost:  0.21302603 \n",
      "Prediction:\n",
      " [[1.2703737 ]\n",
      " [1.7604978 ]\n",
      " [1.2230458 ]\n",
      " [0.6192084 ]\n",
      " [0.9350053 ]\n",
      " [0.75505066]\n",
      " [0.31459212]\n",
      " [0.29320693]]\n",
      "90 Cost:  0.21301264 \n",
      "Prediction:\n",
      " [[1.2703531 ]\n",
      " [1.7604766 ]\n",
      " [1.2230284 ]\n",
      " [0.61919534]\n",
      " [0.9349897 ]\n",
      " [0.7550355 ]\n",
      " [0.31458196]\n",
      " [0.29319647]]\n",
      "91 Cost:  0.21299931 \n",
      "Prediction:\n",
      " [[1.2703325 ]\n",
      " [1.7604556 ]\n",
      " [1.2230111 ]\n",
      " [0.6191822 ]\n",
      " [0.934974  ]\n",
      " [0.7550203 ]\n",
      " [0.31457174]\n",
      " [0.29318613]]\n",
      "92 Cost:  0.21298593 \n",
      "Prediction:\n",
      " [[1.2703118 ]\n",
      " [1.7604345 ]\n",
      " [1.2229937 ]\n",
      " [0.6191692 ]\n",
      " [0.93495846]\n",
      " [0.7550051 ]\n",
      " [0.3145616 ]\n",
      " [0.29317576]]\n",
      "93 Cost:  0.21297252 \n",
      "Prediction:\n",
      " [[1.2702912 ]\n",
      " [1.7604132 ]\n",
      " [1.2229764 ]\n",
      " [0.6191561 ]\n",
      " [0.9349428 ]\n",
      " [0.75499004]\n",
      " [0.3145514 ]\n",
      " [0.29316533]]\n",
      "94 Cost:  0.21295922 \n",
      "Prediction:\n",
      " [[1.2702706 ]\n",
      " [1.7603922 ]\n",
      " [1.2229593 ]\n",
      " [0.619143  ]\n",
      " [0.9349271 ]\n",
      " [0.75497484]\n",
      " [0.31454125]\n",
      " [0.29315498]]\n",
      "95 Cost:  0.21294582 \n",
      "Prediction:\n",
      " [[1.27025   ]\n",
      " [1.760371  ]\n",
      " [1.2229419 ]\n",
      " [0.61912996]\n",
      " [0.9349115 ]\n",
      " [0.75495976]\n",
      " [0.3145311 ]\n",
      " [0.29314452]]\n",
      "96 Cost:  0.21293247 \n",
      "Prediction:\n",
      " [[1.2702293 ]\n",
      " [1.76035   ]\n",
      " [1.2229245 ]\n",
      " [0.6191169 ]\n",
      " [0.9348958 ]\n",
      " [0.75494456]\n",
      " [0.3145209 ]\n",
      " [0.2931342 ]]\n",
      "97 Cost:  0.21291909 \n",
      "Prediction:\n",
      " [[1.2702088 ]\n",
      " [1.7603288 ]\n",
      " [1.2229072 ]\n",
      " [0.61910385]\n",
      " [0.93488014]\n",
      " [0.7549295 ]\n",
      " [0.3145107 ]\n",
      " [0.29312378]]\n",
      "98 Cost:  0.2129057 \n",
      "Prediction:\n",
      " [[1.2701882 ]\n",
      " [1.7603077 ]\n",
      " [1.2228898 ]\n",
      " [0.6190908 ]\n",
      " [0.9348644 ]\n",
      " [0.7549143 ]\n",
      " [0.31450054]\n",
      " [0.29311338]]\n",
      "99 Cost:  0.21289235 \n",
      "Prediction:\n",
      " [[1.2701676 ]\n",
      " [1.7602866 ]\n",
      " [1.2228725 ]\n",
      " [0.6190777 ]\n",
      " [0.93484885]\n",
      " [0.7548991 ]\n",
      " [0.31449038]\n",
      " [0.29310298]]\n",
      "100 Cost:  0.21287899 \n",
      "Prediction:\n",
      " [[1.270147 ]\n",
      " [1.7602654]\n",
      " [1.2228551]\n",
      " [0.6190646]\n",
      " [0.9348333]\n",
      " [0.754884 ]\n",
      " [0.3144802]\n",
      " [0.2930926]]\n"
     ]
    }
   ],
   "source": [
    "# 정규화 \n",
    "# 라이브러리 사용하기.. 굳이 만들필요 없음\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "#정규화 \n",
    "xy =MinMaxScaler().fit_transform(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5) #겁나 작은 Learning Rate\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daefebd",
   "metadata": {},
   "source": [
    "## MNIST 실습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d123d163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T01:18:48.579691Z",
     "start_time": "2022-01-11T01:18:48.562738Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be60a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T01:19:02.197082Z",
     "start_time": "2022-01-11T01:18:56.932780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000 (60000, 28, 28) (60000,)\n",
      "10000 10000 (10000, 28, 28) (10000,)\n",
      "Epoch: 0001, Cost: 0.980638519\n",
      "Epoch: 0002, Cost: 0.350010924\n",
      "Epoch: 0003, Cost: 0.222882439\n",
      "Epoch: 0004, Cost: 0.164799537\n",
      "Epoch: 0005, Cost: 0.170798402\n",
      "Epoch: 0006, Cost: 0.190340132\n",
      "Epoch: 0007, Cost: 0.165829947\n",
      "Epoch: 0008, Cost: 0.147425882\n",
      "Epoch: 0009, Cost: 0.260747701\n",
      "Epoch: 0010, Cost: 0.243906236\n",
      "Epoch: 0011, Cost: 0.283090378\n",
      "Epoch: 0012, Cost: 0.149902052\n",
      "Epoch: 0013, Cost: 0.166950227\n",
      "Epoch: 0014, Cost: 0.167597922\n",
      "Epoch: 0015, Cost: 0.164780913\n",
      "Accuracy:  0.7808\n",
      "random_idx :  574\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#소스코드 문제로 댓글에 있는 정상코드 붙여넣음 / 정확도는 낮음..\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(len(x_train), len(y_train), x_train.shape, y_train.shape)\n",
    "print(len(x_test), len(y_test), x_test.shape, y_test.shape)\n",
    "\n",
    "x_train, x_test = x_train/255.0, x_test/255.0   #Feature scaling 적용\n",
    "\n",
    "nb_classes = 10;\n",
    "\n",
    "x_train_new = x_train.reshape(len(x_train), 784)         #60000 * 784 배열로 변경 - 한행당 이미지 하나 \n",
    "y_train_new = np.zeros((len(y_train), nb_classes))       #60000 * 10 배열 생성\n",
    "for i in range(len(y_train_new)):                        \n",
    "  y_train_new[i,y_train[i]] = 1                          #one-hot encoding \n",
    "\n",
    "x_test_new = x_test.reshape(len(x_test), 784)         #60000 * 784 배열로 변경 - 한행당 이미지 하나 \n",
    "y_test_new = np.zeros((len(y_test), nb_classes))       #60000 * 10 배열 생성\n",
    "for i in range(len(y_test_new)):                        \n",
    "  y_test_new[i,y_test[i]] = 1                          #one-hot encoding \n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])   #6만개의 학습에 대한 10개의 가설 결과\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))  #가설이 10개이고 가설별로 784개의 weigh을 가짐, 즉 7840개의 w\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))       #가설이 10개니 가설의 b도 10\n",
    "\n",
    "# Hypothesis (using softmax)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)  #60000 x 10 행렬 - 행별로 열의 값을 확율로 바꿈 \n",
    "\n",
    "#cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15  # 전체 데이터 셋을 다 학습시키는 횟수 = epoch 1, 총 15번 학습 시키는 것\n",
    "batch_size = 100  #한번에 몇개씩 학습시킬 것인가. \n",
    "total_batch = int(len(x_train_new) / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            #print (epoch,batch_size )\n",
    "            batch_xs = x_train_new[(epoch * batch_size):(epoch + 1) * batch_size]     \n",
    "            batch_ys = y_train_new[(epoch * batch_size):(epoch + 1) * batch_size]\n",
    "\n",
    "            _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += cost_val / total_batch\n",
    "            \n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: x_test_new, Y: y_test_new}\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Get one and predict\n",
    "    random_idx = random.randrange(1,10000)\n",
    "    print (\"random_idx : \", random_idx)\n",
    "    print(\n",
    "        \"Prediction: \",\n",
    "        sess.run(tf.argmax(hypothesis, 1), feed_dict={X: x_test_new[random_idx : random_idx + 1]}),\n",
    "    )\n",
    "\n",
    "    plt.imshow(\n",
    "        x_test_new[random_idx : random_idx + 1].reshape(28, 28),\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909628d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
